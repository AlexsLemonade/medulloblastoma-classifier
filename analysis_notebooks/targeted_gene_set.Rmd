---
title: "Targeted gene set model performance"
author: "Steven Foltz"
date: "2025"
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
    df_print: paged
---

# Rationale

Experiments that generate RNA expression data may use a targeted gene panel as a more cost-effective approach to analyze a subset of genes thought to have greater relevance for disease, especially in clinical settings.
However, when a model is trained using whole transcriptome data, the genes selected for that model will generally show only partial or no overlap with a targeted gene panel.
Even though kTSP and RF models can tolerate missing genes, prediction performance on new samples will likely suffer as a result of having fewer gene:gene comparisons to score.
A model trained using a targeted panel of genes from the start could be applied to sample data that includes more genes, however there may be a decrease in model performance due to starting with a smaller feature space.
This leads to two key questions:

1. Given a targeted gene set of cancer-related genes, how does model performance compare between targeted gene set models and full gene set models?
2. Does the identity of the genes in the targeted gene set matter? In other words, can a random gene set of the same size perform just as well as the targeted gene set?

We will use the [Nanostring nCounter PanCancer IO 360 Panel](https://nanostring.com/products/ncounter-assays-panels/oncology/pancancer-io-360/) targeted gene set published by Nanostring, available for download [here](https://nanostring.com/products/ncounter-assays-panels/panel-selection-tool/) and found in this repository at `processed_data/NS_IO_360_v1.0_Genes.tsv`.

# Setup

```{r setup}

# collect random model metrics? takes significant time if TRUE
# automatically happens if random_plot_df_filepath file does not exist
collect_random_model_metrics <- FALSE

# Source code and libraries
source(here::here("utils/color_schemes.R"))
source(here::here("utils/modeling.R"))
source(here::here("utils/convert_gene_names.R"))
library(patchwork)

# Define directories and input/output file paths
processed_data_dir <- here::here("processed_data")
models_dir <- here::here("models")
random_models_dir <- here::here(models_dir, "targeted_gene_set_random")
plots_dir <- here::here("plots")
plots_data_dir <- here::here(plots_dir, "data")

bulk_genex_filepath <- here::here(processed_data_dir, "bulk_genex.tsv")
bulk_metadata_filepath <- here::here(processed_data_dir, "bulk_metadata.tsv")

baseline_filepath <- here::here(models_dir, "baseline.rds")
targeted_filepath <- here::here(models_dir, "targeted_gene_set.rds")

baseline_plot_df_filepath <- here::here(plots_data_dir, "baseline_plots_df.tsv")
targeted_plot_df_filepath <- here::here(plots_data_dir, "targeted_plot_df.tsv")
random_plot_df_filepath <- here::here(plots_data_dir, "random_plot_df.tsv")

# set subgroups analyzed in this notebook (canonical MB subgroups)
mb_subgroups <- c("G3", "G4", "SHH", "WNT")

# Read in essential data
bulk_genex_df <- readr::read_tsv(bulk_genex_filepath,
                                 show_col_types = FALSE) |>
  tibble::column_to_rownames(var = "gene")

bulk_metadata_df <- readr::read_tsv(bulk_metadata_filepath,
                                    show_col_types = FALSE) |>
  dplyr::filter(sample_accession %in% names(bulk_genex_df),
                subgroup %in% mb_subgroups)

bulk_genex_df <- bulk_genex_df |>
  dplyr::select(dplyr::all_of(bulk_metadata_df$sample_accession))

check_input_files(genex_df = bulk_genex_df,
                  metadata_df = bulk_metadata_df)

```

# How many genes in the targeted panel?

```{r}

# targeted genes (Nanostring IO 360 gene panel)
targeted_genes_filepath <- file.path(processed_data_dir,
                                     "NS_IO_360_v1.0_Genes.tsv")

targeted_genes_df <- readr::read_tsv(file = targeted_genes_filepath,
                                     show_col_types = FALSE)

n_targeted_genes_original <- nrow(targeted_genes_df)

# convert targeted gene set from SYMBOL to ENSEMBL
targeted_genes_df <- targeted_genes_df |>
  convert_gene_names(gene_column_before = "Gene",
                     gene_column_after = "gene",
                     map_from = "SYMBOL",
                     map_to = "ENSEMBL",
                     ah_date = "2022-10-30")

# reduce bulk genex df to overlap with targeted genes
bulk_genex_df_targeted <- bulk_genex_df[row.names(bulk_genex_df) %in% targeted_genes_df$gene, ]

n_targeted_genes_overlap <- nrow(bulk_genex_df_targeted)

```

The original targeted gene set (Nanostring IO 360 gene panel) comprised `r n_targeted_genes_original` genes.
After overlapping with our expression data, there were `r n_targeted_genes_overlap` genes remaining.

# Could we have used MM2S or medulloPackage for this?

## MM2S 

```{r}

suppressMessages(library(MM2S))

# convert overlapping targeted gene set from ENSEMBL to ENTREZID for MM2S
targeted_genes_df_ENTREZID <- bulk_genex_df_targeted |>
  tibble::rownames_to_column(var = "gene") |>
  convert_gene_names(gene_column_before = "gene",
                     gene_column_after = "gene",
                     map_from = "ENSEMBL",
                     map_to = "ENTREZID",
                     ah_date = "2022-10-30")

# MM2S uses pathways defined by genes in HumanGMT$genesets
# Only pathways with between 20-100 genes overlapping with expression data are scored
n_mm2s_common_pathways <- purrr::map(MM2S::HumanGMT$genesets,
                                     \(x) sum(x %in% targeted_genes_df_ENTREZID$gene)) |>
  purrr::map_lgl(\(x) x >= 20 & x <= 100) |>
  sum() # = total number of pathways matching gene overlap criteria for scoring

# MM2S assumes there are at least 24 pathways that get scored
ifelse(n_mm2s_common_pathways >= 24,
       "We can use MM2S!", "We cannot use MM2S.")

```

MM2S uses a pathway-based approach, and those pathways are pre-defined in `MM2S::HumanGMT$genesets`.
To return a GSVA score for a particular pathway, MM2S requires that between 20 and 100 genes overlap between the test data and the set of genes in that pathway.
MM2S later requires that there are at least 24 such pathways in the data.
However, with our targeted gene set, only `r n_mm2s_common_pathways` pathways match the `20 <= overlapping genes <= 100` criteria.
MM2S fails to run because an `NA` value is introduced to `FeatureSelection` and `NorthcottFeatures` inside `MM2S::MM2S.human`, resulting in invalid column selection in `HumanTestGSVA <- HumanTestGSVA[, NorthcottFeatures, drop = FALSE]`.

## medulloPackage

medulloPackage also fails to run.

# Gather targeted, random, and baseline data

```{r}

targeted_list <- readr::read_rds(targeted_filepath)

model_types <- c("ktsp_weighted", "ktsp_unweighted",
                 "rf_weighted", "rf_unweighted",
                 "lasso")

# targeted model metrics
targeted_plot_df <- targeted_list |>
  purrr::map(return_model_metrics,
             model_types = model_types,
             metadata_df = bulk_metadata_df,
             labels = mb_subgroups,
             platforms = c("Array", "RNA-seq")) |>
  purrr::list_rbind(names_to = "repeat_index") |>
  dplyr::mutate(model_type = dplyr::case_match(model_type,
                                               "ktsp_weighted" ~ "kTSP (w)",
                                               "ktsp_unweighted" ~ "kTSP (unw)",
                                               "rf_weighted" ~ "RF (w)",
                                               "rf_unweighted" ~ "RF (unw)",
                                               "lasso" ~ "LASSO"))

readr::write_tsv(x = targeted_plot_df,
                 file = targeted_plot_df_filepath)

# random model metrics
# run collection of random model metrics (set TRUE in setup chunk) if random models have changed since last rendering
# or runs automatically if random_plot_df_filepath does not exist
if (collect_random_model_metrics | !file.exists(random_plot_df_filepath)) {

random_plot_df <- list.files(random_models_dir,
                             pattern = "*.rds",
                             full.names = TRUE) |>
  purrr::map(\(x) readr::read_rds(x) |>
               purrr::map(return_model_metrics,
                          model_types = model_types,
                          metadata_df = bulk_metadata_df,
                          labels = mb_subgroups,
                          platforms = c("Array", "RNA-seq")) |>
               purrr::list_rbind(names_to = "repeat_index") |>
               dplyr::mutate(model_type = dplyr::case_match(model_type,
                                                            "ktsp_weighted" ~ "kTSP (w)",
                                                            "ktsp_unweighted" ~ "kTSP (unw)",
                                                            "rf_weighted" ~ "RF (w)",
                                                            "rf_unweighted" ~ "RF (unw)",
                                                            "lasso" ~ "LASSO"))) |>
  purrr::list_rbind(names_to = "random_index")

readr::write_tsv(x = random_plot_df,
                 file = random_plot_df_filepath)

} else {
  
  random_plot_df <- readr::read_tsv(file = random_plot_df_filepath)
  
}

# baseline model metrics
baseline_plot_df <- readr::read_tsv(file = baseline_plot_df_filepath,
                                    show_col_types = FALSE) |>
  dplyr::filter(model_type %in% c("kTSP (w)", "kTSP (unw)",
                                  "RF (w)", "RF (unw)",
                                  "LASSO"))

# combined dfs
compare_metrics_plot_df <- dplyr::bind_rows(targeted_plot_df |>
                                              dplyr::mutate(gene_set = "Targeted"),
                                            random_plot_df |>
                                              dplyr::mutate(gene_set = "Random"),
                                            baseline_plot_df |>
                                              dplyr::mutate(gene_set = "Full"))

```

# Compare model performance

## Kappa

```{r}

pd <- ggplot2::position_jitterdodge(jitter.height = 0,
                                    jitter.width = 0, 
                                    dodge.width = 0.25,
                                    seed = 1)

kappa_plot_object <- compare_metrics_plot_df |>
  dplyr::filter(metric == "Kappa",
                gene_set %in% c("Full", "Targeted")) |>
  dplyr::mutate(pairing = stringr::str_c(repeat_index, platform)) |>
  ggplot2::ggplot(ggplot2::aes(x = gene_set,
                               y = value)) +
  ggplot2::geom_boxplot(outlier.shape = NA) +
  ggplot2::geom_line(ggplot2::aes(fill = gene_set,
                                  group = pairing),
                     color = "black",
                     position = pd) +
  ggplot2::geom_point(ggplot2::aes(color = gene_set,
                                   group = pairing),
                      position = pd,
                      show.legend = FALSE,
                      size = 2,
                      shape = 16) +
  ggplot2::scale_y_continuous(limits = c(NA,1)) +
  ggplot2::facet_grid(platform ~ model_type) +
  ggplot2::labs(x = "Gene set",
                y = "Kappa",
                title = "Kappa comparison across gene sets") +
  ggplot2::theme_bw()

kappa_plot_object

```

Interpretation:

- kTSP and RF models show significantly higher Kappa values in Array data using the full gene set compared to the targeted gene set.
- kTSP model performance also favors the full gene set in RNA-seq data but is not significant.
- RF models show slightly worse performance with the full gene set compared to the targeted gene set. 
- LASSO models showed no significant difference between full and targeted gene sets using either Array or RNA-seq.
- Low-performing RNA-seq outliers from the full gene set may impact overall interpretation of results.

Metrics table: 

```{r}

kappa_wilcox_df <- compare_metrics_plot_df |>
  dplyr::filter(metric == "Kappa",
                gene_set %in% c("Full", "Targeted")) |>
  dplyr::group_by(model_type, platform) |>
  dplyr::arrange(repeat_index) # guarantee order for paired test

kappa_wilcox_test_df <- kappa_wilcox_df |>
  rstatix::wilcox_test(value ~ gene_set, paired = TRUE)

kappa_wilcox_effsize_df <- kappa_wilcox_df |>
  rstatix::wilcox_effsize(value ~ gene_set, paired = TRUE)

kappa_wilcox_test_df |>
  dplyr::left_join(kappa_wilcox_effsize_df,
                   by = c("model_type", "platform", ".y.", "group1", "group2", "n1", "n2")) |>
  dplyr::mutate(p_adj = p.adjust(p, method = "BH")) |>
  #dplyr::filter(p_adj < 0.05) |>
  dplyr::select(-`.y.`) |>
  dplyr::arrange(p_adj) |>
  knitr::kable()

```

## Balanced accuracy

```{r, fig.height=12, fig.width=8}

balanced_accuracy_plot_object_list <- c("Array", "RNA-seq") |>
  purrr::map(\(x) {
    compare_metrics_plot_df |>
      dplyr::filter(platform == x,
                    metric == "Balanced Accuracy",
                    gene_set %in% c("Full", "Targeted")) |>
      dplyr::mutate(pairing = stringr::str_c(repeat_index, platform)) |>
      ggplot2::ggplot(ggplot2::aes(x = gene_set,
                                   y = value)) +
      ggplot2::geom_boxplot(outlier.shape = NA) +
      ggplot2::geom_line(ggplot2::aes(fill = gene_set,
                                      group = pairing),
                         color = "black",
                         position = pd) +
      ggplot2::geom_point(ggplot2::aes(color = gene_set,
                                       group = pairing),
                          position = pd,
                          show.legend = FALSE,
                          size = 2,
                          shape = 16) +
      ggplot2::scale_y_continuous(limits = c(NA,1)) +
      ggplot2::facet_grid(rows = dplyr::vars(subgroup),
                          cols = dplyr::vars(model_type),
                          scales = "free") +
      ggplot2::labs(x = "Gene set",
                    y = "Balanced Accuracy",
                    title = stringr::str_c(x, " data")) +
      ggplot2::theme_bw()
  }
  ) |>
  setNames(c("Array", "RNA-seq"))

balanced_accuracy_plot_object_list[["Array"]] / balanced_accuracy_plot_object_list[["RNA-seq"]] +
  plot_annotation(title = "Balanced accuracy comparison across gene sets and subtype",
                  tag_levels = "A")

```

Overall interpretion:

- Models trained on full gene sets show higher balanced accuracy across MB subtypes than targeted gene sets, except where accuracy is already close to 1

Array data:

- kTSP (unw) models show significantly higher balanced accuracy with full gene sets (vs. targeted gene sets) across all four MB subtypes
- kTSP (w) shows full > targeted in G3, G4, and SHH but not WNT which has near perfect accuracy with both full and targeted
- RF (unw) shows significant difference for SHH and WNT while RF (w) shows significant difference for G3 and G4

RNA-seq data:

- Variability in accuracy across all model types makes significant differences between gene sets harder to observe
- Only kTSP (unw) (G3) and, unexpectedly, LASSO (WNT) show significant difference after p-value correction

Metrics table:

```{r}

accuracy_wilcox_df <- compare_metrics_plot_df |>
  dplyr::filter(metric == "Balanced Accuracy",
                gene_set %in% c("Full", "Targeted")) |>
  dplyr::group_by(model_type, platform, subgroup) |>
  dplyr::arrange(repeat_index) # guarantee order for paired test

accuracy_wilcox_test_df <- accuracy_wilcox_df |>
  rstatix::wilcox_test(value ~ gene_set, paired = TRUE)

# Effect size function can't handle it when all the paired values have a difference of 0.
# To know which groups that fail condition applies to, look for NA p value from previous step

accuracy_wilcox_effsize_df <- accuracy_wilcox_test_df |>
  dplyr::filter(!is.na(p)) |>
  dplyr::select(model_type, platform, subgroup) |>
  dplyr::left_join(accuracy_wilcox_df,
                   by = c("model_type", "platform", "subgroup")) |>
  dplyr::group_by(model_type, platform, subgroup) |>
  dplyr::arrange(repeat_index) |> # guarantee order for paired test
  rstatix::wilcox_effsize(value ~ gene_set, paired = TRUE)

accuracy_wilcox_test_df |>
  dplyr::left_join(accuracy_wilcox_effsize_df,
                   by = c("model_type", "platform", "subgroup", ".y.", "group1", "group2", "n1", "n2")) |>
  dplyr::mutate(p_adj = p.adjust(p, method = "BH")) |>
  #dplyr::filter(p_adj < 0.05) |>
  dplyr::select(-`.y.`) |>
  dplyr::arrange(p_adj) |>
  knitr::kable()

```


## Targeted permutation test

We want to compare the observed Kappa values against the null distribution of Kappa values (generated using random gene sets).
Observed Kappa values on the far extremes of the null distribution can be considered "significant" if their permutation test p-value is below a given threshold (e.g. < 0.05).
The permutation test p-value is the probability of observing a given Kappa value or something more extreme under the null distribution.
The function `dplyr::percent_rank()` of a variable returns the proportion of values that are less than the observed value (so the percent rank of the max value is 1 without any ties).
The permutation test p-value is then `1 - percent_rank()`.

```{r}

targeted_dots_df <- compare_metrics_plot_df |>
  dplyr::filter(metric == "Kappa",
                gene_set %in% c("Random", "Targeted")) |>
  dplyr::group_by(repeat_index, model_type, platform) |>
  dplyr::mutate(perm_pvalue = 1 - dplyr::percent_rank(value), # see explanatory note above
                perm_pvalue_color = ifelse(perm_pvalue <= 0.05, "<= 0.05", "> 0.05")) |>
  dplyr::filter(gene_set == "Targeted")

targeted_perm_test_plot <- compare_metrics_plot_df |>
  dplyr::filter(metric == "Kappa",
                gene_set == "Random") |>
  dplyr::mutate(repeat_index = factor(repeat_index)) |>
  ggplot2::ggplot(ggplot2::aes(x = value,
                               y = repeat_index)) +
  ggplot2::geom_violin() +
  ggplot2::geom_point(data = targeted_dots_df,
                      mapping = ggplot2::aes(x = value,
                                             y = repeat_index,
                                             color = perm_pvalue_color),
                      shape = 16) +
  ggplot2::facet_grid(cols = dplyr::vars(model_type),
                      rows = dplyr::vars(platform)) +
  ggplot2::scale_color_manual(values = c("<= 0.05" = "red", "> 0.05" = "black")) +
  ggplot2::labs(x = "Kappa",
                y = "Repeat",
                title = "Targeted compared to random gene set Kappa distribution",
                color = "Targeted Kappa\n(permutation p-value)") +
  ggplot2::theme_bw() +
  ggplot2::theme(legend.position = "bottom", legend.direction = "horizontal")

targeted_perm_test_plot

```

Across all models and data types, only 3 out of 100 targeted gene set Kappa values were observed in the extreme upper tail (> 95%) of the random (null) distribution.
Those three were all in RF (unw) models trained on RNA-seq data.
The overall observation is that targeted gene set Kappa values fall within the null distribution of Kappa values returned by random gene sets, meaning there is overall no difference in using targeted and random gene sets of the same size.

# Interpretation

- Full gene sets significantly outperform targeted gene sets, especially in Array data
- Random and targeted gene sets show overall similar performance
- Targeted gene sets may be useful for modeling, but would choose the full gene set if available
- Targeted gene sets cannot be used with existing methods MM2S and medulloPackage

Returning to our two key questions:

1. Given a targeted gene set of cancer-related genes, how does model performance compare between targeted gene set models and full gene set models?

Full gene set models significantly outperform targeted gene set models.
This difference is most striking when predicting MB subgroup labels from Array data.

2. Does the identity of the genes in the targeted gene set matter? In other words, can a random gene set of the same size perform just as well as the targeted gene set?

The identity of the genes used in the targeted gene set appears not to matter.
The performance of targeted gene set models falls within the range of random gene sets of the same size.

# Session info

```{r session_info}
sessionInfo()
```
