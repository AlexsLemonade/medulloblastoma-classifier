---
title: "Train and test baseline models to predict MB subgroups"
author: "Steven Foltz"
date: "2022 - 2023"
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
    df_print: paged
params:
  create_models: FALSE # train new models (if FALSE, reads existing models from file)
  overwrite: FALSE # if create_models is also TRUE, overwrite existing models file
  seed: 44 # set initial seed for run_many_models() and before stochastic plots
  n_repeats: 10 # set number of times to repeat in run_many_models()
  n_cores: 3 # set number of cores to use in run_many_models()
---

# Rationale

We want to use single sample prediction models to predict tumor subgroup in medulloblastoma (MB) patient samples.
Our gene expression data comes from multiple studies, and different studies were generated using different platforms (array and RNA-seq).

Our goals are to train different prediction models (kTSP, RF, MM2S, and LASSO) and to assess model performance on a per-platform and per-subgroup basis.
Ideally, models would perform well regardless of the platform or subgroup of the sample, but differences in sample size mean some groups may be underrepresented in the data available for training.
Inverse-weighting may boost performance for smaller groups, and we can test this in kTSP and RF models using parameters for weighted (w) and unweighted (unw) analyses.

To train and test our models, we use the `run_many_models()` function.
This function allows us to specify what model types we want to analyze, various model parameters, and segregate samples into training/testing sets via a random seed.
We train and test each model a number of times (e.g. 10 repeats) using different training/testing sets to understand the range of model performance as measured by Kappa and Balanced Accuracy.
Training/testing sets segregate at the study level, rather than the sample level.


# Setup

```{r setup}

# get input parameters
create_models <- params$create_models
overwrite <- params$overwrite

# Source code and libraries
source(here::here("utils/color_schemes.R"))
source(here::here("utils/convert_gene_names.R"))
source(here::here("utils/modeling.R"))
library(patchwork)

# Define directories and input/output file paths
processed_data_dir <- here::here("processed_data")
models_dir <- here::here("models")
plots_dir <- here::here("plots")
plots_data_dir <- file.path(plots_dir, "data")

bulk_genex_filepath <- file.path(processed_data_dir, "bulk_genex.tsv")
bulk_metadata_filepath <- file.path(processed_data_dir, "bulk_metadata.tsv")

gene_map_filepath <- file.path(processed_data_dir, "gene_map.tsv")

baseline_filepath <- file.path(models_dir, "baseline.rds")

baseline_plot_df_filepath <- file.path(plots_data_dir, "baseline_plots_df.tsv")
baseline_kappa_plot_filepath <- file.path(plots_dir, "baseline_kappa.pdf")
baseline_accuracy_plot_filepath <- file.path(plots_dir, "baseline_accuracy.pdf")
baseline_binary_TSP_plot_filepath <- file.path(plots_dir, "baseline_binary_TSP.pdf")
baseline_figure_filepath <- file.path(plots_dir, "baseline_figure.pdf")

# check that existing baseline model file will not be overwritten if overwrite is FALSE
if (create_models &
    (file.exists(baseline_filepath)) &
    !overwrite) {
  
  stop("Model output file already exists and overwrite is set to FALSE in analysis_notebooks/baseline.Rmd.")
  
}

# check that files exist if create_models is FALSE
if (!create_models & !file.exists(baseline_filepath)) {
  
  stop("Model output file does not exist and create_models is set to FALSE in analysis_notebooks/baseline.Rmd.")
  
}

# set subgroups analyzed in this notebook (canonical MB subgroups)
mb_subgroups <- c("G3", "G4", "SHH", "WNT")

# Read in essential data
bulk_genex_df <- readr::read_tsv(bulk_genex_filepath,
                                 show_col_types = FALSE) |>
  tibble::column_to_rownames(var = "gene")

bulk_metadata_df <- readr::read_tsv(bulk_metadata_filepath,
                                    show_col_types = FALSE) |>
  dplyr::filter(sample_accession %in% names(bulk_genex_df),
                subgroup %in% mb_subgroups)

bulk_genex_df <- bulk_genex_df |>
  dplyr::select(dplyr::all_of(bulk_metadata_df$sample_accession))

check_input_files(genex_df = bulk_genex_df,
                  metadata_df = bulk_metadata_df)

```

# Train and test MB subgroup models

### Create kTSP, RF, MM2S, and LASSO models

The following code creates both weighted and unweighted kTSP and RF models.
The MM2S and LASSO models use default settings.
Out of all the repeats, we select one 'official' repeat for visualization.
The 'official' repeat maximizes the median Kappa across all models within the repeat.
Supplying the same `initial_seed` to each instance of `run_many_models()` ensures the training/testing sets of each repeat are the same for each model.

```{r}

model_types <- c("ktsp_weighted", "ktsp_unweighted",
                 "rf_weighted", "rf_unweighted",
                 "lasso", "mm2s")

if (create_models) {
  
  # kTSP and RF models with ktsp_weighted = TRUE and rf_weighted = TRUE (defaults)
  weighted_kTSP_RF_models_list <- run_many_models(genex_df = bulk_genex_df,
                                                  metadata_df = bulk_metadata_df,
                                                  labels = mb_subgroups,
                                                  model_types = c("ktsp", "rf"),
                                                  initial_seed = params$seed,
                                                  n_repeats = params$n_repeats,
                                                  n_cores = params$n_cores,
                                                  ktsp_featureNo = 1000,
                                                  ktsp_n_rules_min = 5,
                                                  ktsp_n_rules_max = 50,
                                                  ktsp_weighted = TRUE,
                                                  rf_num.trees = 500,
                                                  rf_genes_altogether = 50,
                                                  rf_genes_one_vs_rest = 50,
                                                  rf_gene_repetition = 1,
                                                  rf_rules_altogether = 50,
                                                  rf_rules_one_vs_rest = 50,
                                                  rf_weighted = TRUE)
  
  # Add _weighted to names of kTSP and RF list elements
  weighted_kTSP_RF_models_list <- weighted_kTSP_RF_models_list |>
    purrr::map(\(x) setNames(x,
                             dplyr::case_match(names(x),
                                               "ktsp" ~ "ktsp_weighted",
                                               "rf" ~ "rf_weighted")))
  
  # kTSP and RF models with ktsp_weighted = FALSE and rf_weighted = FALSE
  unweighted_kTSP_RF_models_list <- run_many_models(genex_df = bulk_genex_df,
                                                    metadata_df = bulk_metadata_df,
                                                    labels = mb_subgroups,
                                                    model_types = c("ktsp", "rf"),
                                                    initial_seed = params$seed,
                                                    n_repeats = params$n_repeats,
                                                    n_cores = params$n_cores,
                                                    ktsp_featureNo = 1000,
                                                    ktsp_n_rules_min = 5,
                                                    ktsp_n_rules_max = 50,
                                                    ktsp_weighted = FALSE,
                                                    rf_num.trees = 500,
                                                    rf_genes_altogether = 50,
                                                    rf_genes_one_vs_rest = 50,
                                                    rf_gene_repetition = 1,
                                                    rf_rules_altogether = 50,
                                                    rf_rules_one_vs_rest = 50,
                                                    rf_weighted = FALSE)
  
  # Add _unweighted to names of kTSP and RF list elements
  unweighted_kTSP_RF_models_list <- unweighted_kTSP_RF_models_list |>
    purrr::map(\(x) setNames(x,
                             dplyr::case_match(names(x),
                                               "ktsp" ~ "ktsp_weighted",
                                               "rf" ~ "rf_weighted")))
  
  # merge weighted and unweighted kTSP and RF model lists
  kTSP_RF_models_list <- purrr::map2(weighted_kTSP_RF_models_list,
                                     unweighted_kTSP_RF_models_list,
                                     c)
  
  # MM2S and LASSO models
  mm2s_lasso_models_list <- run_many_models(genex_df = bulk_genex_df,
                                            metadata_df = bulk_metadata_df,
                                            labels = mb_subgroups,
                                            model_types = c("mm2s", "lasso"),
                                            initial_seed = params$seed,
                                            n_repeats = params$n_repeats,
                                            n_cores = params$n_cores,
                                            mm2s_gene_map_filepath = gene_map_filepath)
  
  # merge kTSP, RF, MM2S, and LASSO model lists
  baseline_list <- purrr::map2(kTSP_RF_models_list,
                               mm2s_lasso_models_list,
                               c) |>
    purrr::map(\(x) x[!duplicated(names(x))]) # remove duplicate list items
  
  # select "official" repeat with greatest median Kappa across models
  official_model <- baseline_list |>
    purrr::map_dbl(\(x) model_types |>
                     purrr::map_dbl(
                       \(mtype) x[[mtype]]$cm$overall[["Kappa"]]) |>
                     median()) |>
    which.max()
  
  for (model_index in 1:length(baseline_list)) {
    
    if (model_index == official_model) {
      
      baseline_list[[model_index]][["official_model"]] <- TRUE
      
    } else {
      
      baseline_list[[model_index]][["official_model"]] <- FALSE
      
    }
    
  }
  
  # write models to file
  readr::write_rds(x = baseline_list,
                   file = baseline_filepath)
  
} else { # if create_models = FALSE and models already exist
  
  baseline_list <- readr::read_rds(baseline_filepath)
  
}

```

# Visualize Kappa and accuracy results

### Gather data

The variable `baseline_list` is a list of lists.
The first level of lists correspond to different repeats using different training/testing sets.
Within each repeat, there are list elements corresponding to particular model results (e.g., `ktsp_weighted` or `lasso`) as well as metadata about the repeat (e.g., the seed used for to determine training/testing sets).
To create a data frame for plotting, we need to gather modeling metrics (Kappa and Balanced Accuracy) from each model across all the repeats.

```{r}

plot_df <- baseline_list |>
  purrr::map(return_model_metrics,
             model_types = model_types,
             metadata_df = bulk_metadata_df,
             labels = mb_subgroups,
             platforms = c("Array", "RNA-seq")) |>
  purrr::list_rbind(names_to = "repeat_index") |>
  dplyr::mutate(model_type = dplyr::case_match(model_type,
                                               "ktsp_unweighted" ~ "kTSP (unw)",
                                               "ktsp_weighted" ~ "kTSP (w)",
                                               "rf_unweighted" ~ "RF (unw)",
                                               "rf_weighted" ~ "RF (w)",
                                               "mm2s" ~ "MM2S",
                                               "lasso" ~ "LASSO"))

readr::write_tsv(x = plot_df,
                 file = baseline_plot_df_filepath)

```

### Kappa tables

Kappa measures how often our predicted subgroups agree with the true subgroups, accounting for the chance of random agreement (necessary when subgroups are imbalanced).
Kappa is an overall measure that applies to an entire set of predictions across subgroups.
Values of Kappa closer to 1 indicate higher agreement, and values closer to 0 indicate random assignment.

$$ \kappa = \frac{p_o - p_e}{1 - p_e} $$

where $p_o$ is the observed proportion of agreement and $p_e$ is the expected proportion of chance agreement.

The following table summarizes Kappa values stratified by platform (Array or RNA-seq) and model type by showing the median Kappa value.

```{r}

plot_df |>
  dplyr::filter(metric == "Kappa") |>
  dplyr::group_by(platform, model_type) |>
  dplyr::summarize(median_kappa = median(value),
                   .groups = "drop") |>
  tidyr::pivot_wider(names_from = platform,
                     values_from = median_kappa) |>
  knitr::kable(caption = "Median Kappa values (by platform)")

```

- Models perform slightly better on Array test data (mid-.90s) than RNA-seq test data (low-.90s) (except for MM2S).
- kTSP (w) and kTSP (unw) show no difference in performance in Array test data (more Array data in training set), but kTSP (unw) outperformed kTSP (w) in RNA-seq test data (against expectation)
- The reverse is true for RF models, with RF (w) outperforming RF (unw) for both Array and RNA-seq test data
- In weighted models, RF outperformed kTSP in RNA-seq, while the unweighted kTSP outperformed RF in both platforms
- MM2S showed better test performance in RNA-seq data despite the original model being trained on Array

### Plot Kappa

```{r}

set.seed(params$seed)

baseline_kappa_plot <- plot_df |>
  dplyr::filter(metric == "Kappa") |>
  ggplot2::ggplot(ggplot2::aes(x = value,
                               y = model_type,
                               color = platform)) +
  ggplot2::geom_violin(draw_quantiles = 0.5,
                       position = ggplot2::position_dodge(0.7),
                       show.legend = FALSE) +
  ggplot2::geom_point(shape = 16,
                      position = ggplot2::position_jitterdodge(jitter.width = 0.1,
                                                               jitter.height = 0)) +
  ggplot2::coord_cartesian(xlim = c(0.7,1)) +
  ggplot2::facet_wrap(~ subgroup,
                      ncol = 1) +
  ggplot2::labs(x = "Kappa",
                y = NULL,
                color = "Platform") +
  ggplot2::scale_color_manual(values = platform_colors) + 
  ggplot2::scale_fill_manual(values = c("#FFFFFF", "#FFFFFF")) + 
  ggplot2::theme_bw() +
  ggplot2::theme(strip.background = ggplot2::element_blank())

ggplot2::ggsave(filename = baseline_kappa_plot_filepath,
                plot = baseline_kappa_plot,
                height = 7,
                width = 7)

baseline_kappa_plot

```

To aid in visualization, the following data points were excluded from the previous plot.
Later we explore this [excluded data point](#excluded-data-point) in more detail.

```{r}

plot_df |>
  dplyr::filter(metric == "Kappa",
                value < 0.7)

```

### Accuracy tables

Balanced accuracy is the average sensitivity and specificity of a model and is measured per subgroup.

$$ \text{Balanced Accuracy} = \frac{Sensitivity + Specificity}{2} $$

where

$$ \text{Sensitivity} = \frac{TP}{TP + FN} \text{ and Specificity} = \frac{TN}{TN + FP} $$

for true and false positive and negative predictions.

The following table summarizes Balanced Accuracy values stratified by model type separately for each platform (Array or RNA-seq) by showing the median Kappa value.

#### Array test data

```{r}

plot_df |>
  dplyr::filter(metric == "Balanced Accuracy",
                platform == "Array") |>
  dplyr::group_by(model_type, subgroup) |>
  dplyr::summarize(median_accuracy = median(value),
                   .groups = "drop") |>
  tidyr::pivot_wider(names_from = subgroup,
                     values_from = median_accuracy) |>
knitr::kable(caption = "Median Balanced Accuracy values")

```

#### RNA-seq test data

```{r}

plot_df |>
  dplyr::filter(metric == "Balanced Accuracy",
                platform == "RNA-seq") |>
  dplyr::group_by(model_type, subgroup) |>
  dplyr::summarize(median_accuracy = median(value),
                   .groups = "drop") |>
  tidyr::pivot_wider(names_from = subgroup,
                     values_from = median_accuracy) |>
  knitr::kable(caption = "Median Balanced Accuracy values")

```

- Overall, prediction models show excellent sensitivity and specificity, with subgroup performance G3 < G4 < SHH < WNT for Array and G4 < G3 < SHH < WNT for RNA-seq
- We observed the largest discrepancy in model performance with G3 predictions using MM2S with Array test data (as previously documented by MM2S authors), but kTSP, RF, and LASSO methods can improve on it
- Notably MM2S G3 predictions with RNA-seq data showed more comparable performance with the other methods

The following plot illustrates the differences observed between model types in G3 subgroup Balanced Accuracy.

### Plot accuracy (G3 only)

```{r}

set.seed(params$seed)

baseline_accuracy_plot <- plot_df |>
  dplyr::filter(metric == "Balanced Accuracy",
                subgroup %in% c("G3")) |>
  ggplot2::ggplot(ggplot2::aes(x = value,
                               y = model_type,
                               color = platform)) +
  ggplot2::geom_violin(draw_quantiles = 0.5,
                       show.legend = FALSE,
                       position = ggplot2::position_dodge(0.7)) +
  ggplot2::geom_point(shape = 16,
                      position = ggplot2::position_jitterdodge(jitter.width = 0.1,
                                                               jitter.height = 0)) +
  ggplot2::facet_wrap(~ subgroup,
                      ncol = 1) +
  ggplot2::coord_cartesian(xlim = c(0.6,1)) +
  ggplot2::labs(x = "Balanced Accuracy",
                y = NULL,
                color = "Platform") +
  ggplot2::scale_fill_manual(values = c("#FFFFFF", "#FFFFFF")) +
  ggplot2::scale_color_manual(values = platform_colors) + 
  ggplot2::theme_bw() +
  ggplot2::theme(strip.background = ggplot2::element_blank())

ggplot2::ggsave(filename = baseline_accuracy_plot_filepath,
                plot = baseline_kappa_plot,
                height = 7,
                width = 7)

baseline_accuracy_plot

```

To aid in visualization, the following data points were excluded from the previous plot.
Later we explore this [excluded data point](#excluded-data-point) in more detail.
```{r}

plot_df |>
  dplyr::filter(metric == "Balanced Accuracy",
                subgroup %in% c("G3"),
                value < 0.6)

```

### Excluded data point

What's up with the LASSO model on RNA-seq data from repeat 9?
Note, this analysis will be specific to the particular data sets and parameters used in the original creation of this notebook.

```{r}

lasso_rnaseq_repeat_9_df <- baseline_list[[9]]$test_metadata |>
  dplyr::filter(platform == "RNA-seq") |>
  dplyr::left_join(baseline_list[[9]]$lasso$test_results$predicted_labels_df,
                   by = "sample_accession")

calculate_confusion_matrix(predicted_labels = lasso_rnaseq_repeat_9_df$predicted_labels,
                           true_labels = lasso_rnaseq_repeat_9_df$subgroup,
                           labels = mb_subgroups)$table


```

For this repeat (only), the model predicts almost all samples to be SHH!

### kTSP (w) binary rules plot

```{r}

official_model <- baseline_list |>
  purrr::map_lgl("official_model") |>
  which()
official_train_test_seed <- baseline_list[[official_model]]$train_test_seed
official_ktsp_model <- baseline_list[[official_model]][["ktsp_weighted"]]$classifier
official_ktsp_test_results <- baseline_list[[official_model]][["ktsp_weighted"]]$test_results$model_output


train_test_samples_list <- get_train_test_samples(genex_df = bulk_genex_df,
                                                  metadata_df = bulk_metadata_df,
                                                  train_test_seed = official_train_test_seed,
                                                  proportion_of_studies_train = 0.5)

# confirm it's the same test samples in the same order
if (any(train_test_samples_list$test != row.names(official_ktsp_test_results))) {
  
  stop("Testing sets do not match!")
  
} else { # use train_test_samples_list and classifier to visualize binary rules
  
  genex_df_test <- bulk_genex_df |>
    dplyr::select(train_test_samples_list$test)
  metadata_df_test <- bulk_metadata_df |>
    dplyr::filter(sample_accession %in% train_test_samples_list$test)
  
  test_data_object <- multiclassPairs::ReadData(Data = genex_df_test,
                                                Labels = metadata_df_test$subgroup,
                                                Platform = metadata_df_test$platform,
                                                verbose = FALSE)
  
  # The plot_binary_TSP() output cannot be saved to a variable directly, but
  # saving the plot as a function call makes it available to call again later
  # Source: https://stackoverflow.com/a/46961131
  binary_TSP_plot <- \() {multiclassPairs::plot_binary_TSP(Data = test_data_object,
                                                           classifier = official_ktsp_model, 
                                                           prediction = official_ktsp_test_results, 
                                                           classes = mb_subgroups,
                                                           show_rule_name = FALSE,
                                                           show_platform = FALSE,
                                                           ref_col = subgroup_colors,
                                                           pred_col = subgroup_colors,
                                                           legend = FALSE,
                                                           anno_height = 0.05,
                                                           score_height = 0.05,
                                                           margin = c(0, 5, 0, 0.5))}
  
  ggplot2::ggsave(filename = baseline_binary_TSP_plot_filepath,
                  plot = binary_TSP_plot(),
                  width = 7,
                  height = 7)

}

```

### kTSP (w) confusion matrix

```{r}
  
baseline_list[[official_model]][["ktsp_weighted"]]$cm

```

# Baseline figure

```{r}

panel_a_b <- baseline_kappa_plot + baseline_accuracy_plot +
  patchwork::plot_layout(guides = "collect")
panel_c <- patchwork::wrap_elements(full = ~ binary_TSP_plot())

figure_plot <- panel_a_b / panel_c +
  patchwork::plot_annotation(tag_levels = 'a') +
  patchwork::plot_layout(nrow = 2,
                         heights = c(1,2))

ggplot2::ggsave(filename = baseline_figure_filepath,
                plot = figure_plot,
                width = 7.5,
                height = 6)

figure_plot

```

# Session info

```{r session_info}
sessionInfo()
```
